Management Studio
Haga una tabla de bitácora que contenga los siguientes campos:
- Identity (PK)
- Fecha Inicial de datos
- Fecha Final de datos
- Cantidad de Registros Procesados
- Fecha de Inicio de Ejecución Etapa 1
- Fecha de Fin de Ejecución Etapa 1
- Fecha de Inicio de Ejecución Etapa 2
- Fecha de Fin de Ejecución Etapa 2
****- Fecha de Inicio de Ejecución Etapa 3
**** - Fecha de Fin de Ejecución Etapa 3
- Estado
	+ 0: En Construcción
	+ 1: Listo para ejecutar
	+ 2: Error Etapa 1
	+ 3: Error Etapa 2
	+ 4: Error Etapa 3
	+ 10: Finalizado exitoso
Inserte varios registros a la tabla para que tenga elementos que no se traslapen en las fechas de datos
	
Haga un paquete en Integration Services el cual consulta la tabla de bitácora para buscar el registro más antiguo que no esté ni "En Construcción" ni en "Finalizado exitoso" y que:
- si está en Estado 1, pasa a ejecutar algún Data Flow 1, otro Data Flow 2 y otro Data Flow 3.
- si está en Estado 2, pasa a ejecutar algún Data Flow 2 y otro Data Flow 3.
- si está en Estado 3, pasa a ejecutar algún Data Flow 3.
- cuando termine de pasar por el Data Flow 3, pasa a estado 10.

Condiciones generales de ejecución:
- Si una tarea falla en Data Flow "n", el registro queda en el estado "Error Etapa n".
- Para que una tarea pase exitosamente por una etapa, la cantidad de segundos del sistema multiplicada por 13 debe ser múltiplo de la etapa más un número.
- Debe respetar las fechas de ejecución de las Etapas anteriores que no se van a repetir en su ejecución.
- Sólo debe asignar las fechas de inicio y fin de ejecución de las Etapas que ejecuta.
- Para que haya alguna duración en el proceso, en lugar de un data flow, puede crear un script task o un sql task para que la máquina se "duerma" una cantidad aleatoria de segundos entre 10 y 40.
- Para asignar la "Cantidad de Registros Procesados", utilice un aleatorio que corresponda a la cantidad de milésimas de segundo que tiene el sistema en ese momento



